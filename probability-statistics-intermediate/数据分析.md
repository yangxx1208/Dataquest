# 数据分析

[TOC]

## list非数值替换/选取特定数值位置的值

~~~python
#list类型不能用map对数值进行替换但是可以用如下方法
survey_responses = ["none", "some", "a lot", "none", "a few", "none", "none"]
survey_scale = ["none" , "a few" , "some" , "a lot"]
survey_numbers = [survey_scale.index(i) for i in survey_responses]
#选取性别为male的工资
gender = ["male", "female", "female", "male", "male", "female"]
savings = [1200, 5000, 3400, 2400, 2800, 4100]
male_saving_list = [savings[i] for i in range(0,len(gender)) if gender[i] == "male"]
~~~

## scipy.stats中统计量

### 偏斜程度&峰态

~~~python
from scipy.stats import skew
skew() #统计数据的偏斜程度，负值偏右，正值偏左
kurtosis() #统计分布的峰态，值约小方差越大越扁平
~~~

### 正太分布

~~~python
from scipy.stats import norm
norm.pdf(data , mean , var) #返回与data值一一对应的均值为mean，方差为var的正太分布
~~~

### 相关系数&皮尔逊系数

~~~python
#相关系数
from scipy.stats.stats import pearsonr
r, p_value = pearsonr(x, y) #返回x,y的相关系数
#先看p值(显著性)，若p值>0.05,相关性系数没有统计学意义。
#无论r值(相关性)大小，都表明两者之间没有相关性。
#如果p值<0.05，那么就表明两者之间有相关性。
#|r|大于等于0.8时为两变量间高度相关；
#|r|大于等于0.5小于0.8时认为两变量中度相关；
#|r|大于等于0.3小于0.5时认为两变量低度相关或弱相关，
#|r|小于0.3说明相关程度为极弱相关或无相关。
~~~

###线性回归

~~~python
#线性回归函数
from scipy.stats import linregress
slope, intercept, r_value, p_value, stderr_slope = linregress(x, y)#slope为斜率， intercept为截距
~~~

### 二项分布&累积密度函数

~~~python
import scipy
from scipy import linspace
from scipy.stats import binom
# Create a range of numbers from 0 to 30, with 31 elements (each number has one entry).
outcome_counts = linspace(0,30,31)
# Create the binomial probabilities, one for each entry in outcome_counts.
dist = binom.pmf(x,n,p)
#x: the list of outcomes,
#n: the total number of events,
#p: the probability of the outcome we're interested in seeing.
plt.bar(outcome_counts, dist)
plt.show()
#二项分布 均值：np 均方差：sqrt(npq)
#二项分布累积密度函数
outcome_probs = binom.cdf(outcome_counts,30,0.39)
~~~

###卡方检验

~~~python
#手动计算期望值
import numpy as np
from scipy.stats import chisquare
observed = np.array([6662, 1179, 15128, 9592])#观测值
expected = np.array([5249.8, 2597.4, 16533.5, 8180.3])#期望值
chisq_value, pvalue_gender_income = chisquare(observed, expected)

#import pandas
from scipy.stats import chi2_contingency
table = pandas.crosstab(income["sex"], [income["race"]])#频数表
chisq_value, pvalue_gender_race, df, expected = chi2_contingency(table)
~~~



## numpy统计量函数

### 统计量

~~~python
numpy.median() #中值（series无）
numpy.sum() #和
numpy.mean() #均值
~~~

### 协方差

~~~python
from numpy import cov
covar = cov(x, y) #返回下x,y的协方差矩阵
~~~

## dataframe中crosstab函数

~~~python
import pandas
table = pandas.crosstab(income["sex"], [income["race"]]) #返回频数分布表（也可以指定values）
~~~



## series统计量

~~~python
series.mean() #均值
series.sum() #和
series.var() #方差（与手动计算值有出入）
series.std() #标准差（与手动计算值有出入）
~~~



## 画图：设置水平|垂直线

~~~python
plt.axvline() #设置水平线
plt.axhline() #设置垂直线
~~~

## 数据清洗——dropna

~~~python
df.dropna() #将有空值的行删除
df.dropna(subset = [column]) #删除指定column为空值的行
~~~

## random抽样

~~~python
import random
num = random.randint(0, 10) #在0~1之间随机生产一个整数（包括端点）
random.seed(10) #设置随机种子，种子相同，生成的数据也相同
random.sample(data, num) #随机选取data中的num个数据，seed相同时，每次选取的数据也相同
~~~

## math阶乘

~~~python
import math
math.factorial(N) 
#组合数
def find_outcome_combinations(N, k):
    # Calculate the numerator of our formula.
    numerator = math.factorial(N)
    # Calculate the denominator.
    denominator = math.factorial(k) * math.factorial(N - k)
    # Divide them to get the final value.
    return numerator / denominator
~~~

## dictionary中get操作

~~~python
empty = {}

# Since "a" isn't a key in empty, the value False is returned.
key_a = empty.get("a", False):

empty["b"] = "boat"

# key_b is the value for the key "b" in empty.
key_b = empty.get("b", False):
# "boat" is assigned to key_b.
~~~

## 排列检验

* 背景

  排列检验是一种验证数据显著性的假设检验，如有两组数据，查看两组数据是否有区别

* 思路

  将两组数据的均值差求出来记为diff，讲数据打乱，用random函数随机分组，如此迭代N次，计算每次的均值差，从而得到一个分布。计算分布中均值差大于等于diff的概率，记为p_value。

* p_value即为显著性检验值，若p值大于0.05，说明该事件发生不是因为有突发因素，而是符合分布的，若p值小于0.05，该事件发生是显著的。

 ### P_Value

​	 A p-value allows us to determine whether the difference between two values is due to chance, or due to an underlying difference.